{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#karthave minnichekane\n",
    "\n",
    "pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "unbalanced parenthesis at position 8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 36\u001b[0m\n\u001b[0;32m     25\u001b[0m answer_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m1) AI is the simulation of human intelligence in machines that are programmed to think, reason, learn, and solve problems like humans.\u001b[39m\n\u001b[0;32m     27\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124m4) Computer vision is a field of AI that enables machines to interpret and analyze visual data like images and videos.\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Parse the input\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m answers_dict \u001b[38;5;241m=\u001b[39m \u001b[43mparse_answer_sheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer_sheet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Print the result\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(answers_dict)\n",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m, in \u001b[0;36mparse_answer_sheet\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     14\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ms*(.+?)(?=\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124md+\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m)|$)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Find all matches\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDOTALL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Create a dictionary with question numbers as keys and answers as values\u001b[39;00m\n\u001b[0;32m     20\u001b[0m result \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mint\u001b[39m(num): answer\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m num, answer \u001b[38;5;129;01min\u001b[39;00m matches}\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\re\\__init__.py:216\u001b[0m, in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfindall\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    209\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m \n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfindall(string)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\re\\__init__.py:294\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is an undocumented flag \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout an obvious purpose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    293\u001b[0m               \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m--> 294\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43m_compiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (flags \u001b[38;5;241m&\u001b[39m DEBUG):\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_cache) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m _MAXCACHE:\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# Drop the oldest item\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\re\\_compiler.py:745\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[0;32m    744\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m--> 745\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\re\\_parser.py:994\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munbalanced parenthesis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mgrouprefpos:\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mgroups:\n",
      "\u001b[1;31merror\u001b[0m: unbalanced parenthesis at position 8"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def parse_answer_sheet(text):\n",
    "    \"\"\"\n",
    "    Splits the input text into a dictionary of answers based on question numbers.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing all answers with question numbers.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with question numbers as keys and answers as values.\n",
    "    \"\"\"\n",
    "    # Regular expression to match question numbers and answers\n",
    "    pattern = r\"(\\\\d+)\\\\)\\\\s*(.+?)(?=\\\\n\\\\d+\\\\)|$)\"\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Create a dictionary with question numbers as keys and answers as values\n",
    "    result = {int(num): answer.strip() for num, answer in matches}\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example input\n",
    "answer_sheet = \"\"\"\n",
    "1) AI is the simulation of human intelligence in machines that are programmed to think, reason, learn, and solve problems like humans.\n",
    "\n",
    "2) Machine learning is a subset of AI that enables machines to learn and improve from data without being explicitly programmed.\n",
    "\n",
    "3) Deep learning is a subset of ML that uses neural networks with many layers to model complex patterns in data.\n",
    "\n",
    "4) Computer vision is a field of AI that enables machines to interpret and analyze visual data like images and videos.\n",
    "\"\"\"\n",
    "\n",
    "# Parse the input\n",
    "answers_dict = parse_answer_sheet(answer_sheet)\n",
    "\n",
    "# Print the result\n",
    "print(answers_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'AI is the simulation of human intelligence in machines that are programmed to think, reason, learn, and solve problems like humans.', 2: 'Machine learning is a subset of AI that enables machines to learn and improve from data without being explicitly programmed.', 3: 'Deep learning is a subset of ML that uses neural networks with many layers to model complex patterns in data.', 4: 'Computer vision is a field of AI that enables machines to interpret and analyze visual data like images and videos.'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_answer_sheet(response):\n",
    "    \"\"\"\n",
    "    Splits the input text into a dictionary of answers based on question numbers.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing all answers with question numbers.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with question numbers as keys and answers as values.\n",
    "    \"\"\"\n",
    "    # Correct regex pattern (fixed escaping of parentheses)\n",
    "    pattern = r\"(\\d+)\\)\\s*(.+?)(?=\\n\\d+\\)|$)\"\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = re.findall(pattern, response, re.DOTALL)\n",
    "    \n",
    "    # Create a dictionary with question numbers as keys and answers as values\n",
    "    result = {int(num): answer.strip() for num, answer in matches}\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example input\n",
    "answer_sheet = \"\"\"\n",
    "1) AI is the simulation of human intelligence in machines that are programmed to think, reason, learn, and solve problems like humans.\n",
    "\n",
    "2) Machine learning is a subset of AI that enables machines to learn and improve from data without being explicitly programmed.\n",
    "\n",
    "3) Deep learning is a subset of ML that uses neural networks with many layers to model complex patterns in data.\n",
    "\n",
    "4) Computer vision is a field of AI that enables machines to interpret and analyze visual data like images and videos.\n",
    "\"\"\"\n",
    "\n",
    "# Parse the input\n",
    "answers_dict = parse_answer_sheet(answer_sheet)\n",
    "\n",
    "# Print the result\n",
    "print(answers_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Hacktopia\\LazyGrader\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file 'Document 5.pdf' as: https://generativelanguage.googleapis.com/v1beta/files/u2na2mowqi6i\n",
      "Waiting for file processing...\n",
      "...all files ready\n",
      "\n",
      "1) AI is the simulation of human intelligence in\n",
      "machines that are programmed to think, reason,\n",
      "learn, and solve problems like humans.\n",
      "\n",
      "2) Machine learning is a subset of AI that\n",
      "enables machine to learn and improve from\n",
      "data without being explicitly programmed.\n",
      "\n",
      "3) Deep learning is a subset of ML that uses\n",
      "neural networks with many layers to model\n",
      "complex patterns in data.\n",
      "\n",
      "4) Computer vision is a field of AI that\n",
      "enables machine to interpret and analyze\n",
      "visual data like images and videos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "import re\n",
    "\n",
    "class Hand2Text:\n",
    "    def __init__(self):\n",
    "        \n",
    "        genai.configure(api_key='AIzaSyD8MpIOSHL5RAnM6X9D4M5x8fxk1BtH7aw')\n",
    "        self.generation_config = {\n",
    "            \"temperature\": 1,\n",
    "            \"top_p\": 0.95,\n",
    "            \"top_k\": 40,\n",
    "            \"max_output_tokens\": 8192,\n",
    "            \"response_mime_type\": \"text/plain\",\n",
    "        }\n",
    "        self.model = genai.GenerativeModel(\n",
    "            model_name=\"gemini-1.5-flash\",\n",
    "            generation_config=self.generation_config,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def upload_to_gemini(path, mime_type=None):\n",
    "        \"\"\"Uploads the given file to Gemini and returns the file object.\"\"\"\n",
    "        file = genai.upload_file(path, mime_type=mime_type)\n",
    "        print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
    "        return file\n",
    "\n",
    "    @staticmethod\n",
    "    def wait_for_files_active(files):\n",
    "        \"\"\"Waits for the uploaded files to be processed and become active.\"\"\"\n",
    "        print(\"Waiting for file processing...\")\n",
    "        for name in (file.name for file in files):\n",
    "            file = genai.get_file(name)\n",
    "            while file.state.name == \"PROCESSING\":\n",
    "                print(\".\", end=\"\", flush=True)\n",
    "                time.sleep(10)\n",
    "                file = genai.get_file(name)\n",
    "            if file.state.name != \"ACTIVE\":\n",
    "                raise Exception(f\"File {file.name} failed to process\")\n",
    "        print(\"...all files ready\")\n",
    "        print()\n",
    "\n",
    "    \n",
    "\n",
    "    def transcribe_answer_sheet(self, pdf_path):\n",
    "        \"\"\"Uploads a PDF, waits for processing, and transcribes it into text.\"\"\"\n",
    "        # Upload the file\n",
    "        file = self.upload_to_gemini(pdf_path, mime_type=\"application/pdf\")\n",
    "        \n",
    "        # Wait for the file to be active\n",
    "        self.wait_for_files_active([file])\n",
    "\n",
    "        # Start the chat session\n",
    "        chat_session = self.model.start_chat(\n",
    "            history=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"parts\": [\n",
    "                        file,\n",
    "                        \"\"\"\n",
    "                        You are an AI designed to transcribe and format examination answer sheets. Your task is to extract answers from a student's response and provide them in a structured format. Follow these guidelines:\n",
    "\n",
    "                        Structure each answer starting with the question number, followed by the answer, like this:\n",
    "                        Ensure the numbering is sequential and accurate.\n",
    "                        Avoid unnecessary introductory text like: \"Here is the text:\" ,\"This is the answer:\".\n",
    "                        Any greetings, acknowledgments, or unrelated information.\n",
    "                        Preserve the formatting of the content exactly as provided, without adding any extra words or phrases.\n",
    "                        Ensure each question's number and answer are clearly separated. Do not merge answers into a single paragraph.\n",
    "                        Do not include any additional explanations or comments unrelated to the answers. Only provide clean, structured text as described above.\n",
    "                            \"\"\",\n",
    "                            ],\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Send the transcription request\n",
    "        response = chat_session.send_message(\"Start transcription.\")\n",
    "\n",
    "        return response.text\n",
    "    \n",
    "    def parse_responses(self,response):\n",
    "        \n",
    "        pattern = r\"(\\d+)\\)\\s*(.+?)(?=\\n\\d+\\)|$)\"\n",
    "        matches = re.findall(pattern, response, re.DOTALL)\n",
    "        result = {int(num): answer.strip() for num, answer in matches}\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        hand2text = Hand2Text()\n",
    "        transcribed_text = hand2text.transcribe_answer_sheet(\"Document 5.pdf\")\n",
    "        \n",
    "        print(transcribed_text)\n",
    "        #hand2text.parse_responses(transcribed_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Groq' from partially initialized module 'fake_answers' (most likely due to a circular import) (e:\\Hacktopia\\LazyGrader\\fake_answers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfake_answers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Groq\n",
      "File \u001b[1;32me:\\Hacktopia\\LazyGrader\\fake_answers.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfake_answers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Groq\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSentimentAnalyzer\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Groq' from partially initialized module 'fake_answers' (most likely due to a circular import) (e:\\Hacktopia\\LazyGrader\\fake_answers.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from fake_answers import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment for: I'm so sorry, but I'm a large language model, I don't have the ability to access real-time weather information. However, I can give you a fun fact about the weather!\n",
      "\n",
      "Since I'm a digital AI assistant, I don't have direct access to real-time weather data. But if you want to know the current weather conditions, you can easily check your local weather forecasting app, website, or TV for the latest updates. Simply type \"weather\" along with your city or zip code to access current and forecasted conditions!\n",
      "\n",
      "Would you like to know more about weather tips or a general overview of weather-related trivia?\n",
      "Sentiment Analysis: Neutral\n",
      "AI Response: I'm so sorry, but I'm a large language model, I don't have the ability to access real-time weather information. However, I can give you a fun fact about the weather!\n",
      "\n",
      "Since I'm a digital AI assistant, I don't have direct access to real-time weather data. But if you want to know the current weather conditions, you can easily check your local weather forecasting app, website, or TV for the latest updates. Simply type \"weather\" along with your city or zip code to access current and forecasted conditions!\n",
      "\n",
      "Would you like to know more about weather tips or a general overview of weather-related trivia?\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self) -> None:\n",
    "        self.client = Groq(api_key='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')\n",
    "\n",
    "    def analyze_sentiment(self, text):\n",
    "        # Mocking the sentiment analysis functionality\n",
    "        print(\"Analyzing sentiment for:\", text)\n",
    "        sentiment = \"Positive\" if \"good\" in text else \"Neutral\"\n",
    "        return sentiment\n",
    "\n",
    "\n",
    "class Brain:\n",
    "    def __init__(self) -> None:\n",
    "        self.client = Groq(api_key='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')\n",
    "        self.sentiment_analyzer = SentimentAnalyzer()\n",
    "\n",
    "    def generate_response(self, message):\n",
    "        # Send the message to the model independently (no history)\n",
    "        chat_completion = self.client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": message}],\n",
    "            model=\"llama3-8b-8192\",\n",
    "        )\n",
    "\n",
    "        # Retrieve the assistant's response\n",
    "        response = chat_completion.choices[0].message.content\n",
    "        \n",
    "        # Perform sentiment analysis (optional)\n",
    "        sentiment = self.sentiment_analyzer.analyze_sentiment(response)\n",
    "        print(\"Sentiment Analysis:\", sentiment)\n",
    "\n",
    "        # Return the response\n",
    "        return response\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    brain = Brain()\n",
    "\n",
    "    # Example message to generate a response\n",
    "    message = \"\"\n",
    "    response = brain.generate_response(message)\n",
    "    print(\"AI Response:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
